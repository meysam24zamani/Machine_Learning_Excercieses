setwd("~/Downloads/lab5_deliver_191214")
require(XML)
install.packages("XML")
require(tm)
install.packages("tm")
require(igraph)
doc <- xmlTreeParse("languagesAbstracts.rdf", useInternalNodes = TRUE)
require(XML)
doc <- xmlTreeParse("languagesAbstracts.rdf", useInternalNodes = TRUE)
root <- xmlRoot(doc)
langV <- c()
abstrV <- c()
chl <- getNodeSet(doc, "//res:solution")
for(i in 1:xmlSize(chl)){
node <- chl[[i]]
chl2 <- xmlChildren(node)
binding1 <- chl2[[1]]
binding2 <- chl2[[2]]
langID <- xmlGetAttr(xmlChildren(binding1)[[2]],"rdf:resource")
abstract <- xmlValue(xmlChildren(binding2)[[2]])
#print(langID)
#print(abstract)
langV <- c(langV, langID)
abstrV <- c(abstrV, abstract)
}
languages.df <- data.frame(langV, abstrV)
xkcd.corpus <- Corpus(DataframeSource(data.frame(as.character(languages.df[, 2]))))
xkcd.corpus <- tm_map(xkcd.corpus, removePunctuation)
lang.corpus <- tm_map(xkcd.corpus, content_transformer(tolower))
lang.corpus <- tm_map(lang.corpus, function(x) removeWords(x, stopwords("english")))
tdm <- TermDocumentMatrix(lang.corpus)
require(tm)
xkcd.corpus <- Corpus(DataframeSource(data.frame(as.character(languages.df[, 2]))))
xkcd.corpus <- tm_map(xkcd.corpus, removePunctuation)
lang.corpus <- tm_map(xkcd.corpus, content_transformer(tolower))
lang.corpus <- tm_map(lang.corpus, function(x) removeWords(x, stopwords("english")))
tdm <- TermDocumentMatrix(lang.corpus)
tdm
size(tdm)
N.docs <- length(lang.corpus)
tfidfWeights <- function(tf.vec, df) {
# Computes tfidf weights from a term frequency vector and a document
# frequency scalar
weight = rep(0, length(tf.vec))
weight[tf.vec > 0] = (1 + log2(tf.vec[tf.vec > 0])) * log2(N.docs/df)
weight
}
weightsPerTermVec <- function(tfidf.row) {
term.df <- sum(tfidf.row[1:N.docs] > 0)
tf.idf.vec <- tfidfWeights(tfidf.row, term.df)
return(tf.idf.vec)
}
term.doc.matrix <- as.matrix(tdm)
tfidf.matrix <- t(apply(term.doc.matrix, c(1), FUN = weightsPerTermVec))
tfidf.matrix <- scale(tfidf.matrix, center = FALSE, scale = sqrt(colSums(tfidf.matrix^2)))
#constructing a graph for first 5 most similar documents
accum <- c()
#for(i in 1:N.docs){
for (i in 1:5) {
query.vector <- tfidf.matrix[, (i)]
doc.scores <- t(query.vector) %*% tfidf.matrix
results.df <- data.frame(doc = languages.df$langV, score = t(doc.scores))
results.df <- results.df[order(results.df$score, decreasing = TRUE), ]
print("-----------------")
similarLangs=head(results.df, 5)
src <- as.String(similarLangs[1,1])
for (j in 2:5){
dest <- as.String(similarLangs[j,1])
accum <- c(accum, src, dest)
}
}
el <- matrix(accum, nc=2, byrow=TRUE)
g <- graph.edgelist(el)
plot(g)
summary(g)
library (igraph)
g <- edges(1,2,1,3,2,3,3,3)
plot(g)
g <- graph.empty() + edges(1,2,1,3,2,3,3,3)
g <- graph(1,2,1,3,2,3,3,3)
g <- graph(c(1,2,1,3,2,3,3,3))
plot(g)
V(g)
page.rank(g)
page.rank(g, damping=0.9)
v <- page.rank(g, damping=0.9)$vector
v
sum(v)
v*3
a=v*3
a[1]
a[2]
a[3]
a[2]+a[3]
a[1]+a[3]
v <- page.rank(g, damping=0.7)$vector
a=v*3
a
a[2]+a[3]
quit()
5/4
dotchart(c(1,2,-3,-7))
dotchart(c(1,2,-3,-7), pch=1)
dotchart(c(1,2,-3,-7), pch=2)
dotchart(c(1,2,-3,-7), pch='+')
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','-','-'))
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','-','-'),xlab=NA,ylab=NA)
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','-','-'),xlab=NA,ylab=NA,ylim=c(0,0))
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','-','-'),xlab=NA,ylab=NA,ylim=c(0,1))
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','-','-'),xlab=NA,ylab=NA,ylim=c(0,0.1))
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','--','--'),xlab=NA,ylab=NA,ylim=c(0,0.1))
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','--','--'),xlab=NA,ylab=NA,ylim=c(0,0.1),col=c('red','red','blue','blue'))
plot(c(1,2,-3,-7),c(0,0,0,0), pch= c('+','+','--','--'),xlab=NA,ylab=NA,ylim=c(0,0.1),xlim=c(-10,10),col=c('red','red','blue','blue'))
install.packages(c("MASS", "Rcpp"))
install.packages("plotly")
library(plotly)
set.seed(100)
d <- diamonds[sample(nrow(diamonds), 1000), ]
plot_ly(d, x = carat, y = price, text = paste("Clarity: ", clarity),
mode = "markers", color = carat, size = carat)
p <- ggplot(data = d, aes(x = carat, y = price)) +
geom_point(aes(text = paste("Clarity:", clarity)), size = 4) +
geom_smooth(aes(colour = cut, fill = cut)) + facet_wrap(~ cut)
(gg <- ggplotly(p))
library(plotly)
df <- read.csv("https://raw.githubusercontent.com/plotly/datasets/master/2011_us_ag_exports.csv")
df$hover <- with(df, paste(state, '<br>', "Beef", beef, "Dairy", dairy, "<br>",
"Fruits", total.fruits, "Veggies", total.veggies,
"<br>", "Wheat", wheat, "Corn", corn))
# give state boundaries a white border
l <- list(color = toRGB("white"), width = 2)
# specify some map projection/options
g <- list(
scope = 'usa',
projection = list(type = 'albers usa'),
showlakes = TRUE,
lakecolor = toRGB('white')
)
plot_ly(df, z = total.exports, text = hover, locations = code, type = 'choropleth',
locationmode = 'USA-states', color = total.exports, colors = 'Purples',
marker = list(line = l), colorbar = list(title = "Millions USD"),
filename="r-docs/usa-choropleth") %>%
layout(title = '2011 US Agriculture Exports by State<br>(Hover for breakdown)', geo = g)
quit()
library(igraph)
library(igraph)
g <- sample_smallworld(1, 4, 4, 0)
plot(g)
g <- sample_smallworld(1, 10, 4, 0)
plot(g)
plot(g, layout=layout_in_circle())
plot(g, layout=layout_in_circle
plot(g, layout=layout_in_circle)
plot(g, layout=layout_in_circle(g))
g <- sample_smallworld(1, 10, 2, 0)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
ring(10)
g=ring(10)
plot(g)
g=make_ring(10)
plot(g)
g <- make_ring(10)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
g <- make_ring(4)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
g <- make_ring(5)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
g <- make_ring(6)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
g <- make_ring(10)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
g <- make_ring(8)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
g <- make_ring(7)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
g <- make_ring(6)
plot(g, layout=layout_in_circle(g))
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
make_lattice(length=3, dim=2)
g=make_lattice(length=3, dim=2)
plot(g)
g <- make_lattice(length=3, dim=2)
plot(g, layout=layout_in_circle(g))
g <- make_lattice(length=3, dim=2)
plot(g)
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
g <- make_lattice(dimvector=c(3,2))
plot(g)
diameter(g)
transitivity(g, type="local")
degree.distribution(g)
betweenness(g)
closeness(g)
degree(g)
quit()
library(MASS)
data(iris3)
Data <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
Data
learn <- sample(1:150, 75)
learn
table(Data$Sp[learn])
mydata.learn <- Data[learn, ]
mydata.test <- Data[-learn, ]
pairs(Data[c("Sepal.L.","Sepal.W.","Petal.L.","Petal.W.")], main="Fisher's Iris flowers", pch=22,
bg=c("red", "yellow", "blue")[unclass(Data$Sp)])
mydata.lda <- lda(Sp ~ ., Data, prior = c(1,1,1)/3, subset = learn)
mydata.lda <- lda(Sp ~ ., prior = c(1,1,1)/3, data = mydata.learn)
mydata.lda
plot(mydata.lda)
iris.pred <- predict(mydata.lda)
plot(iris.pred$x,type="n")
text(iris.pred$x,labels=as.character(rownames(iris.pred$x)),col=as.integer(iris.pred$class))
legend('bottomleft', c("setosa", "versicolor", "virginica"), lty=1, col=c('black', 'red', 'green'), bty='n', cex=.4)
predict(mydata.lda, mydata.learn)$class
predict(mydata.lda, mydata.learn)$posterior # the posterior probabilities
mydata.lda.cv <- lda(Sp ~ ., prior = c(1,1,1)/3, data = Data, subset=learn, CV=TRUE)
summary(mydata.lda.cv$class)
(tab <- table(Data$Sp[learn], mydata.lda.cv$class))
(error.LOOCV <- 100*(1-sum(tab[row(tab)==col(tab)])/sum(tab)))
mydata.lda.cv.noPetal.W <- update(mydata.lda.cv, . ~ . - Petal.W.)
(tab <- table(Data$Sp[learn], mydata.lda.cv.noPetal.W$class))
(error.LOOCV <- 100*(1-sum(tab[row(tab)==col(tab)])/sum(tab)))
mydata.qda.cv <- qda(Sp ~ ., prior = c(1,1,1)/3, data = Data, subset=learn, CV=TRUE)
summary(mydata.qda.cv$class)
(tab <- table(Data$Sp[learn], mydata.lda.cv$class))
(error.LOOCV <- 100*(1-sum(tab[row(tab)==col(tab)])/sum(tab)))
mydata.lda <- lda(Sp ~ ., Data, prior = c(1,1,1)/3, subset = learn)
lda.predictions <- predict(mydata.lda, mydata.test)
lda.predictions$class
(tab <- table(Data$Sp[-learn], lda.predictions$class))
(error.TE <- 100*(1-sum(tab[row(tab)==col(tab)])/sum(tab)))
quit()
?glm
p = 0:1:0.05
p = 0:100 / 100
p
b = p / (2 * (1-p))
b
plot (3+b, b)
plot (p, 3+b)
plot (p, 3+b, log=x)
plot (p, 3+b, log="x")
plot (p, 3+b, log="xy")
3+b
plot (p, 3+b, log="xy")
plot (p, b, log="xy")
plot (p, b, log="y")
plot (p, b)
plot (p, b, log="x")
plot (p, b, log="y")
exit
quit
quit()
x = seq(100) - 50
x
x = seq(101) - 51
x
plot(x, exp(x/50 - 1))
plot(x, 10*exp(x/50 - 1))
help(plot)
lines(x, 10*exp(x/50 - 1))
lines(x, 10*exp(x/50 - 1))
lines(x, 10*exp(x/50 - 1))
plot(x, 10*exp(x/50 - 1), type="l")
10*exp(-50/50 - 1)
10*exp(-60/60 - 1)
??nls
install.packages(c("class", "codetools", "mgcv"))
## the MASS library contains the multivariate gaussian
library(MASS)
## the ggplot2 library contains functions for making nice plots
library(ggplot2)
install.packages("ggplot2")
## the ggplot2 library contains functions for making nice plots
library(ggplot2)
set.seed(2226)
## First we need some auxiliary functions
source("auxiliary.R")
setwd("~/Nextcloud/AA1-GCED/labos/L02")
## First we need some auxiliary functions
source("auxiliary.R")
N <- 1000
K <- 5
centre <- c(0,0)
dispersion <- 10
## generate 2D data as a mixture of 5 Gaussians, each axis-aligned (independent variables) with different variances
## the centers and coefficients are chosen randomly
d <- generate.data (N,K,centre,dispersion)
## these are the components of the mixture
plot.mixture (d$locs, d$z, d$obs)
## compute 2D kernel density
z <- kde2d(d$obs[,1], d$obs[,2], n=50)
## some pretty colors
library(RColorBrewer)
colorets <- rev(brewer.pal(11, "RdYlBu"))
## a simpler way of plotting the raw data (what the clustering method sees)
plot(d$obs, xlab="x", ylab="y", pch=19, cex=.4)
## and this is a contour plot of the unconditional density (what the clustering sees)
contour(z, drawlabels=FALSE, nlevels=22, col=colorets, add=TRUE)
abline(h=mean(d$obs[,2]), v=mean(d$obs[,1]), lwd=1)
K <- 2
kmeans2.2 <- cclust (d$obs,K,iter.max=100,method="kmeans",dist="euclidean")
plot(d$obs[,1],d$obs[,2],col=(kmeans2.2$cluster+1))
points(kmeans2.2$centers,bg=seq(1:kmeans2.2$ncenters)+1,cex=2,pch=21,col='black')
(CH2.2 <- clustIndex(kmeans2.2,d$obs, index="calinski"))
K <- 5
# the {cclust} library contains some clustering functions, including k-means
library (cclust)
install.packages("cclust")
# the {cclust} library contains some clustering functions, including k-means
library (cclust)
K <- 2
kmeans2.2 <- cclust (d$obs,K,iter.max=100,method="kmeans",dist="euclidean")
plot(d$obs[,1],d$obs[,2],col=(kmeans2.2$cluster+1))
points(kmeans2.2$centers,bg=seq(1:kmeans2.2$ncenters)+1,cex=2,pch=21,col='black')
(CH2.2 <- clustIndex(kmeans2.2,d$obs, index="calinski"))
K <- 5
kmeans2.5 <- cclust (d$obs,K,iter.max=100,method="kmeans",dist="euclidean")
plot(d$obs[,1],d$obs[,2],col=(kmeans2.5$cluster+1))
points(kmeans2.5$centers,bg=seq(1:kmeans2.5$ncenters)+1,cex=2,pch=21,col='black')
(CH2.5 <- clustIndex(kmeans2.5,d$obs, index="calinski"))
do.kmeans <- function (whatK)
{
r <- cclust (d$obs,whatK,iter.max=100,method="kmeans",dist="euclidean")
(clustIndex(r,d$obs, index="calinski"))
}
max (replicate (100, do.kmeans(5)))
res <- rep(NA,10)
for (K in 2:10)
res[K] <- max (replicate (100, do.kmeans(K)))
plot(res, type="l")
library(Rmixmod)
install.packages("Rmixmod")
library(Rmixmod)
set.seed(2228)
fammodel <- mixmodGaussianModel (family="diagonal", equal.proportions=FALSE)
z <- mixmodCluster (data.frame(d$obs),models = fammodel, nbCluster = 5)
## take your time to understand the output ...
summary(z)
# the final centers
(means <- z@bestResult@parameters@mean)
# in case you want 'hard' assignments
(found.clusters <- z@bestResult@partition)
## the estimated covariance matrices for each cluster
z@bestResult@parameters@variance
## self-explained
z@bestResult@likelihood # (it is actually the log-likelihood)
## the posterior probabilities = 'soft' assignments = the gamma_k(x_n) in class
z@bestResult@proba
plot(d$obs[,1],d$obs[,2],col=(found.clusters+1))
points(means,col=seq(1:5)+1,cex=2,pch=19)
fammodel <- mixmodGaussianModel (family="general", equal.proportions=FALSE)
z <- mixmodCluster (data.frame(d$obs),models = fammodel, nbCluster = 5)
summary(z)
means <- z@bestResult@parameters@mean
found.clusters <- z@bestResult@partition
plot(d$obs[,1],d$obs[,2],col=(found.clusters+1))
points(means,col=seq(1:5)+1,cex=2,pch=19)
## compare the estimated centers
means
# with the truth (note the clusters may appear in a different order)
d$locs
## or the estimated coefficients
sort(z@bestResult@parameters@proportions)
# with the truth
sort(d$coefs)
data("planets", package = "HSAUR")
summary(planets)
install.packages("HSAUR")
data("planets", package = "HSAUR")
summary(planets)
library("rgl")
install.packages("rgl")
library("rgl")
with (planets, plot3d(mass, period, eccen, main = "Exoplanets plot"))
source ("C-H.r")   # gives C.H()
range <- 2:10
chs <- numeric(length(range))
chs
do.kmeans <- function (whatdata, whatK)
{
r <- cclust (whatdata,centers=whatK,iter.max=100,method="kmeans",dist="euclidean")
C.H (r, whatdata)
}
planets.m <- as.matrix(planets)
for (myK in range)
{
chs[myK] <- max (replicate (100, do.kmeans(planets.m, myK)))
}
plot (c(1,range), chs, type='b', xlab="No. of clusters", ylab="C-H index", main="Planet data")
planets.log <- with (planets, as.matrix(cbind(log(mass), log(period), log(eccen+1))))
for (myK in range)
{
chs[myK] <- max (replicate (100, do.kmeans(planets.log, myK)))
}
plot (c(1,range), chs, type='b', xlab="No. of clusters", ylab="C-H index", main="Planet data (log)")
K <- 2
kmeans.planets <- cclust (as.matrix(planets.log),K,iter.max=100,method="kmeans",dist="euclidean")
plot3d (planets.log[,1], planets.log[,2], planets.log[,3], main = "Exoplanets log plot", col=(kmeans.planets$cluster+1))
# let's add cluster centers
material3d (size=10)
points3d(kmeans.planets$centers,col=seq(1:K)+1)
plot3d (planets.log[,1], planets.log[,2], planets.log[,3], main = "Exoplanets log plot", col=(kmeans.planets$cluster+1))
# let's add cluster centers
material3d (size=10)
points3d(kmeans.planets$centers,col=seq(1:K)+1)
fammodel <- mixmodGaussianModel (family="general", equal.proportions=FALSE)
z <- mixmodCluster (data.frame(planets.log), models = fammodel, nbCluster = K)
summary(z)
means <- z@bestResult@parameters@mean
found.clusters <- z@bestResult@partition
plot3d (planets.log[,1], planets.log[,2], planets.log[,3], main = "Exoplanets log plot - EM version", col=(found.clusters+1))
material3d (size=10)
points3d(means, col=seq(1:K)+1)
z <- mixmodCluster (data.frame(planets.log), nbCluster = 2:5)
means <- z@bestResult@parameters@mean
found.clusters <- z@bestResult@partition
plot3d (planets.log[,1], planets.log[,2], planets.log[,3], main = "Exoplanets log plot - EM FINAL version", col=(found.clusters+1))
material3d (size=10)
K <- 3
points3d(means, col=seq(1:K)+1)
z
library(mlbench)
install.packages("mlbench")
library(mlbench)
N <- 1000
K <- 6
# the clusters
data.1 <- mlbench.2dnormals (N,K)
plot(data.1)
plot(x=data.1$x[,1], y=data.1$x[,2])
?mlbench.2dnormals
